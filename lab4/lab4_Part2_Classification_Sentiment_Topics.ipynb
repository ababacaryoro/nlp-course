{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - Part 2: Document Classification, Sentiment Analysis & Topic Modeling\n",
    "\n",
    "**Course:** Natural Language Processing\n",
    "\n",
    "**Objectives:**\n",
    "- Build document classifiers (intro + advanced)\n",
    "- Perform sentiment analysis on different domains\n",
    "- Discover topics using unsupervised learning\n",
    "- Compare different feature extraction methods\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. Complete all exercises marked with `# YOUR CODE HERE`\n",
    "2. **Answer all written questions** in the designated markdown cells\n",
    "3. Save your completed notebook\n",
    "4. **Push to your Git repository and send the link to: yoroba93@gmail.com**\n",
    "\n",
    "### Personal Analysis Required\n",
    "\n",
    "This lab contains questions requiring YOUR personal interpretation. \n",
    "\n",
    "---\n",
    "\n",
    "## Use Cases Covered\n",
    "\n",
    "| Task | Intro Use Case | Advanced Use Case |\n",
    "|------|----------------|-------------------|\n",
    "| Classification | AG News | Legal Documents |\n",
    "| Sentiment Analysis | Amazon Reviews | Twitter |\n",
    "| Topic Modeling | Research Papers | Legal Contracts |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (uncomment if needed)\n",
    "# !pip install datasets scikit-learn nltk pandas numpy matplotlib seaborn wordcloud gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Hugging Face datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common preprocessing function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_simple(text):\n",
    "    \"\"\"Basic preprocessing: lowercase, remove punctuation.\"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def preprocess_advanced(text):\n",
    "    \"\"\"Advanced preprocessing: lowercase, remove punct, stopwords, lemmatize.\"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words and len(t) > 2]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "print(\"Preprocessing functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART A: Document Classification\n",
    "\n",
    "We will work with two use cases:\n",
    "1. **Intro:** News Topic Classification (AG News)\n",
    "2. **Advanced:** Legal Document Classification (LexGLUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.1 Intro: News Topic Classification (AG News)\n",
    "\n",
    "**Scenario:** A media company automatically routes articles to editorial teams.\n",
    "\n",
    "**Feature Extraction:** TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AG News dataset\n",
    "print(\"Loading AG News dataset...\")\n",
    "ag_news = load_dataset(\"ag_news\")\n",
    "\n",
    "# Use subset for faster processing\n",
    "ag_train = pd.DataFrame(ag_news['train']).sample(n=8000, random_state=42)\n",
    "ag_test = pd.DataFrame(ag_news['test']).sample(n=2000, random_state=42)\n",
    "\n",
    "# Label mapping\n",
    "ag_labels = {0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}\n",
    "ag_train['label_name'] = ag_train['label'].map(ag_labels)\n",
    "ag_test['label_name'] = ag_test['label'].map(ag_labels)\n",
    "\n",
    "print(f\"Train: {len(ag_train)}, Test: {len(ag_test)}\")\n",
    "print(f\"\\nCategories: {list(ag_labels.values())}\")\n",
    "print(ag_train['label_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "ag_train['text_clean'] = ag_train['text'].apply(preprocess_simple)\n",
    "ag_test['text_clean'] = ag_test['text'].apply(preprocess_simple)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_ag = None\n",
    "\n",
    "X_train_ag = None\n",
    "X_test_ag = None\n",
    "y_train_ag = ag_train['label']\n",
    "y_test_ag = ag_test['label']\n",
    "\n",
    "print(f\"TF-IDF features: {X_train_ag.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A.1: Train a News Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a Logistic Regression classifier on AG News\n",
    "# 1. Create the classifier\n",
    "# 2. Train it\n",
    "# 3. Make predictions\n",
    "# 4. Calculate accuracy and F1-score (macro)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "clf_ag = None  # Create LogisticRegression\n",
    "\n",
    "# Train\n",
    "\n",
    "# Predict\n",
    "y_pred_ag = None\n",
    "\n",
    "# Evaluate\n",
    "accuracy_ag = None\n",
    "f1_ag = None\n",
    "\n",
    "print(f\"AG News Classification Results:\")\n",
    "print(f\"  Accuracy: {accuracy_ag:.4f}\")\n",
    "print(f\"  F1 (macro): {f1_ag:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_ag, y_pred_ag, target_names=list(ag_labels.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2 Advanced: Legal Document Classification (LexGLUE - ECtHR)\n",
    "\n",
    "**Scenario:** A law firm classifies court decisions by violated articles.\n",
    "\n",
    "**Feature Extraction:** Bag of Words with N-grams\n",
    "\n",
    "**Challenge:** Legal text is longer and uses specialized vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LexGLUE ECtHR dataset (European Court of Human Rights)\n",
    "print(\"Loading LexGLUE ECtHR dataset...\")\n",
    "lex_glue = load_dataset(\"lex_glue\", \"ecthr_a\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "lex_train = pd.DataFrame(lex_glue['train'])\n",
    "lex_test = pd.DataFrame(lex_glue['test'])\n",
    "\n",
    "# Use subset (legal docs are long)\n",
    "lex_train = lex_train.sample(n=min(1500, len(lex_train)), random_state=42)\n",
    "lex_test = lex_test.sample(n=min(500, len(lex_test)), random_state=42)\n",
    "\n",
    "print(f\"Train: {len(lex_train)}, Test: {len(lex_test)}\")\n",
    "print(f\"\\nColumns: {lex_train.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the data structure\n",
    "print(\"Sample legal document (first 500 chars):\")\n",
    "sample_text = ' '.join(lex_train.iloc[0]['text'][:3])  # text is a list of paragraphs\n",
    "print(sample_text[:500])\n",
    "\n",
    "print(f\"\\nLabels (violated articles): {lex_train.iloc[0]['labels']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data: combine text paragraphs and use first label for simplicity\n",
    "def prepare_legal_text(row):\n",
    "    \"\"\"Join text paragraphs and truncate.\"\"\"\n",
    "    full_text = ' '.join(row['text'])\n",
    "    return full_text[:5000]  # Truncate long documents\n",
    "\n",
    "lex_train['full_text'] = lex_train.apply(prepare_legal_text, axis=1)\n",
    "lex_test['full_text'] = lex_test.apply(prepare_legal_text, axis=1)\n",
    "\n",
    "# Use first label (multi-label to single-label for simplicity)\n",
    "lex_train['primary_label'] = lex_train['labels'].apply(lambda x: x[0] if x else -1)\n",
    "lex_test['primary_label'] = lex_test['labels'].apply(lambda x: x[0] if x else -1)\n",
    "\n",
    "# Remove documents without labels\n",
    "lex_train = lex_train[lex_train['primary_label'] >= 0]\n",
    "lex_test = lex_test[lex_test['primary_label'] >= 0]\n",
    "\n",
    "print(f\"Cleaned - Train: {len(lex_train)}, Test: {len(lex_test)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(lex_train['primary_label'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A.2: Build a Legal Document Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the legal document classifier using Bag of Words\n",
    "\n",
    "# Step 1: Preprocess with advanced function\n",
    "lex_train['text_clean'] = lex_train['full_text'].apply(preprocess_advanced)\n",
    "lex_test['text_clean'] = lex_test['full_text'].apply(preprocess_advanced)\n",
    "\n",
    "# Step 2: Create CountVectorizer (Bag of Words) with bigrams\n",
    "# YOUR CODE HERE\n",
    "bow_legal = CountVectorizer(\n",
    "    max_features=___,      # Choose: 3000-5000\n",
    "    ngram_range=___,       # Choose: (1,1), (1,2), or (1,3)\n",
    "    min_df=___,            # Choose: 2-5\n",
    "    max_df=___             # Choose: 0.9-0.99\n",
    ")\n",
    "\n",
    "# Step 3: Transform data\n",
    "X_train_lex = None\n",
    "X_test_lex = None\n",
    "y_train_lex = lex_train['primary_label']\n",
    "y_test_lex = lex_test['primary_label']\n",
    "\n",
    "print(f\"BoW features: {X_train_lex.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a Linear SVM classifier (good for high-dimensional legal text) or other model\n",
    "\n",
    "# YOUR CODE HERE\n",
    "clf_legal = None  # Create LinearSVC\n",
    "\n",
    "# Train\n",
    "\n",
    "# Predict\n",
    "y_pred_lex = None\n",
    "\n",
    "# Evaluate\n",
    "accuracy_lex = None\n",
    "f1_lex = None\n",
    "\n",
    "print(f\"Legal Classification Results:\")\n",
    "print(f\"  Accuracy: {accuracy_lex:.4f}\")\n",
    "print(f\"  F1 (macro): {f1_lex:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written Question A.1 (Personal Interpretation)\n",
    "\n",
    "Compare your results from AG News and Legal classification:\n",
    "\n",
    "1. **Which task achieved higher accuracy?** Why do you think there's a difference?\n",
    "2. **What vectorizer parameters did you choose for legal text?** Justify each choice.\n",
    "3. **What challenges are unique to legal document classification?** (Consider: length, vocabulary, ambiguity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER:**\n",
    "\n",
    "1. Accuracy comparison:\n",
    "   - AG News: ... | Legal: ...\n",
    "   - Reason for difference: ...\n",
    "\n",
    "2. My vectorizer choices:\n",
    "   - max_features=___ because...\n",
    "   - ngram_range=___ because...\n",
    "   - min_df=___ because...\n",
    "   - max_df=___ because...\n",
    "\n",
    "3. Legal classification challenges:\n",
    "   - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART B: Sentiment Analysis\n",
    "\n",
    "We will work with two use cases:\n",
    "1. **Intro:** E-commerce Product Reviews (Amazon)\n",
    "2. **Advanced:** Social Media Sentiment (Twitter/TweetEval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.1 Intro: Amazon Product Reviews\n",
    "\n",
    "**Scenario:** An e-commerce company monitors product sentiment.\n",
    "\n",
    "**Feature Extraction:** TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Amazon Reviews dataset (multilingual, we'll use English)\n",
    "print(\"Loading Amazon Reviews dataset...\")\n",
    "amazon = load_dataset(\"amazon_reviews_multi\", \"en\")\n",
    "\n",
    "# Convert to DataFrame and sample\n",
    "amazon_train = pd.DataFrame(amazon['train']).sample(n=5000, random_state=42)\n",
    "amazon_test = pd.DataFrame(amazon['test']).sample(n=1000, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(amazon_train)}, Test: {len(amazon_test)}\")\n",
    "print(f\"\\nColumns: {amazon_train.columns.tolist()}\")\n",
    "print(f\"\\nStar rating distribution:\")\n",
    "print(amazon_train['stars'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to binary sentiment (1-2 stars = negative, 4-5 stars = positive)\n",
    "# Remove neutral (3 stars) for clearer distinction\n",
    "\n",
    "def to_binary_sentiment(stars):\n",
    "    if stars <= 2:\n",
    "        return 0  # Negative\n",
    "    elif stars >= 4:\n",
    "        return 1  # Positive\n",
    "    else:\n",
    "        return -1  # Neutral (to be removed)\n",
    "\n",
    "amazon_train['sentiment'] = amazon_train['stars'].apply(to_binary_sentiment)\n",
    "amazon_test['sentiment'] = amazon_test['stars'].apply(to_binary_sentiment)\n",
    "\n",
    "# Remove neutral\n",
    "amazon_train = amazon_train[amazon_train['sentiment'] >= 0]\n",
    "amazon_test = amazon_test[amazon_test['sentiment'] >= 0]\n",
    "\n",
    "sentiment_labels = {0: 'Negative', 1: 'Positive'}\n",
    "print(f\"After filtering - Train: {len(amazon_train)}, Test: {len(amazon_test)}\")\n",
    "print(f\"\\nSentiment distribution:\")\n",
    "print(amazon_train['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample reviews\n",
    "print(\"Sample POSITIVE review:\")\n",
    "pos_sample = amazon_train[amazon_train['sentiment'] == 1].iloc[0]\n",
    "print(f\"Product: {pos_sample['product_category']}\")\n",
    "print(f\"Review: {pos_sample['review_body'][:300]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "print(\"Sample NEGATIVE review:\")\n",
    "neg_sample = amazon_train[amazon_train['sentiment'] == 0].iloc[0]\n",
    "print(f\"Product: {neg_sample['product_category']}\")\n",
    "print(f\"Review: {neg_sample['review_body'][:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B.1: Build Amazon Sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build sentiment classifier for Amazon reviews\n",
    "\n",
    "# Step 1: Preprocess\n",
    "amazon_train['text_clean'] = amazon_train['review_body'].apply(preprocess_simple)\n",
    "amazon_test['text_clean'] = amazon_test['review_body'].apply(preprocess_simple)\n",
    "\n",
    "# Step 2: TF-IDF\n",
    "tfidf_amazon = None\n",
    "\n",
    "X_train_amz = None\n",
    "X_test_amz = None\n",
    "y_train_amz = amazon_train['sentiment']\n",
    "y_test_amz = amazon_test['sentiment']\n",
    "\n",
    "# Step 3 & 4: YOUR CODE HERE - Train Naive Bayes and evaluate or choose another model if not suitable\n",
    "clf_amazon = None  # Create MultinomialNB\n",
    "\n",
    "# Train\n",
    "\n",
    "# Predict\n",
    "y_pred_amz = None\n",
    "\n",
    "# Evaluate\n",
    "print(f\"Amazon Sentiment Results:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test_amz, y_pred_amz):.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_amz, y_pred_amz, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze most predictive words\n",
    "feature_names = tfidf_amazon.get_feature_names_out()\n",
    "\n",
    "# For Naive Bayes, use log probabilities\n",
    "neg_probs = clf_amazon.feature_log_prob_[0]\n",
    "pos_probs = clf_amazon.feature_log_prob_[1]\n",
    "log_ratio = pos_probs - neg_probs\n",
    "\n",
    "# Top positive and negative words\n",
    "top_pos_idx = log_ratio.argsort()[-15:]\n",
    "top_neg_idx = log_ratio.argsort()[:15]\n",
    "\n",
    "print(\"Top POSITIVE words:\", [feature_names[i] for i in top_pos_idx])\n",
    "print(\"\\nTop NEGATIVE words:\", [feature_names[i] for i in top_neg_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.2 Advanced: Twitter Sentiment (TweetEval)\n",
    "\n",
    "**Scenario:** A brand monitors social media sentiment about their products.\n",
    "\n",
    "**Feature Extraction:** Bag of Words with character n-grams (better for informal text)\n",
    "\n",
    "**Challenge:** Tweets are short, informal, with hashtags, mentions, and slang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TweetEval sentiment dataset\n",
    "print(\"Loading TweetEval Sentiment dataset...\")\n",
    "tweet_eval = load_dataset(\"tweet_eval\", \"sentiment\")\n",
    "\n",
    "tweet_train = pd.DataFrame(tweet_eval['train'])\n",
    "tweet_test = pd.DataFrame(tweet_eval['test'])\n",
    "\n",
    "# Labels: 0=negative, 1=neutral, 2=positive\n",
    "tweet_labels = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
    "tweet_train['label_name'] = tweet_train['label'].map(tweet_labels)\n",
    "tweet_test['label_name'] = tweet_test['label'].map(tweet_labels)\n",
    "\n",
    "print(f\"Train: {len(tweet_train)}, Test: {len(tweet_test)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(tweet_train['label_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample tweets\n",
    "for label in [0, 1, 2]:\n",
    "    sample = tweet_train[tweet_train['label'] == label].iloc[0]\n",
    "    print(f\"[{tweet_labels[label]}]: {sample['text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special preprocessing for tweets\n",
    "def preprocess_tweet(text):\n",
    "    \"\"\"Preprocess tweet text.\"\"\"\n",
    "    text = str(text).lower()\n",
    "    # Keep @mentions and #hashtags but simplify\n",
    "    text = re.sub(r'@\\w+', '@user', text)  # Replace mentions with @user\n",
    "    text = re.sub(r'http\\S+', 'URL', text)  # Replace URLs\n",
    "    text = re.sub(r'[^a-zA-Z@#\\s]', '', text)  # Keep @ and # symbols\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "tweet_train['text_clean'] = tweet_train['text'].apply(preprocess_tweet)\n",
    "tweet_test['text_clean'] = tweet_test['text'].apply(preprocess_tweet)\n",
    "\n",
    "print(\"Sample preprocessed tweet:\")\n",
    "print(f\"Original: {tweet_train.iloc[0]['text']}\")\n",
    "print(f\"Cleaned:  {tweet_train.iloc[0]['text_clean']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B.2: Build Twitter Sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build a classifier using character n-grams (good for short, informal text)\n",
    "\n",
    "# YOUR CODE HERE: Create a vectorizer with character n-grams\n",
    "# Hint: Use analyzer='char_wb' for word-boundary-aware character n-grams\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer=___,           # 'char_wb' for character n-grams with word boundaries\n",
    "    ngram_range=___,        # Try (2,5) or (3,6) for character n-grams\n",
    "    max_features=___,       # 3000-5000\n",
    "    min_df=___              # 2-5\n",
    ")\n",
    "\n",
    "X_train_tw = None\n",
    "X_test_tw = None\n",
    "y_train_tw = tweet_train['label']\n",
    "y_test_tw = tweet_test['label']\n",
    "\n",
    "print(f\"Character n-gram features: {X_train_tw.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train Logistic Regression and evaluate\n",
    "\n",
    "clf_tweet = None  # YOUR CODE HERE\n",
    "\n",
    "# Train and predict\n",
    "\n",
    "y_pred_tw = None\n",
    "\n",
    "# Evaluate\n",
    "print(f\"Twitter Sentiment Results (3-class):\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test_tw, y_pred_tw):.4f}\")\n",
    "print(f\"  F1 (macro): {f1_score(y_test_tw, y_pred_tw, average='macro'):.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_tw, y_pred_tw, target_names=list(tweet_labels.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_tw = confusion_matrix(y_test_tw, y_pred_tw)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_tw, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=list(tweet_labels.values()),\n",
    "            yticklabels=list(tweet_labels.values()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Twitter Sentiment Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('twitter_sentiment_cm.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written Question B.1 (Personal Interpretation)\n",
    "\n",
    "Compare Amazon vs Twitter sentiment analysis:\n",
    "\n",
    "1. **Which task was harder?** Look at the F1 scores and confusion matrices.\n",
    "2. **Why did you choose those character n-gram parameters for Twitter?** What's the advantage over word n-grams?\n",
    "3. **Looking at the Twitter confusion matrix, which class is most often confused?** Why might this be?\n",
    "4. **Give an example tweet that would be hard to classify correctly.** Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER:**\n",
    "\n",
    "1. Harder task:\n",
    "   - Amazon F1: ... | Twitter F1: ...\n",
    "   - Reason: ...\n",
    "\n",
    "2. Character n-gram choices:\n",
    "   - ngram_range=___ because...\n",
    "   - Advantage over words: ...\n",
    "\n",
    "3. Most confused class:\n",
    "   - Class: ...\n",
    "   - Reason: ...\n",
    "\n",
    "4. Difficult tweet example:\n",
    "   - Tweet: \"...\"\n",
    "   - Why it's hard: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART C: Topic Modeling\n",
    "\n",
    "We will work with two use cases:\n",
    "1. **Intro:** Research Paper Topics (ArXiv)\n",
    "2. **Advanced:** Legal Contract Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.1 Intro: Research Paper Topic Discovery (ArXiv)\n",
    "\n",
    "**Scenario:** A research organization discovers themes in scientific papers.\n",
    "\n",
    "**Method:** LDA (Latent Dirichlet Allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ArXiv papers dataset\n",
    "print(\"Loading ArXiv papers dataset (this may take a moment)...\")\n",
    "arxiv = load_dataset(\"scientific_papers\", \"arxiv\", trust_remote_code=True)\n",
    "\n",
    "# Sample from training set\n",
    "arxiv_df = pd.DataFrame(arxiv['train']).sample(n=2000, random_state=42)\n",
    "\n",
    "print(f\"Loaded {len(arxiv_df)} papers\")\n",
    "print(f\"Columns: {arxiv_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine sample\n",
    "print(\"Sample paper abstract (first 500 chars):\")\n",
    "print(arxiv_df.iloc[0]['abstract'][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess abstracts for topic modeling\n",
    "arxiv_df['abstract_clean'] = arxiv_df['abstract'].apply(preprocess_advanced)\n",
    "\n",
    "# Create document-term matrix with CountVectorizer\n",
    "count_vec_arxiv = None\n",
    "\n",
    "dtm_arxiv = count_vec_arxiv.fit_transform(arxiv_df['abstract_clean'])\n",
    "print(f\"Document-term matrix: {dtm_arxiv.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "n_topics_arxiv = None  # Scientific papers likely have diverse topics. Choose appropriately (8-12).\n",
    "\n",
    "lda_arxiv = LatentDirichletAllocation(\n",
    "    n_components=n_topics_arxiv,\n",
    "    random_state=42,\n",
    "    max_iter=15,\n",
    "    learning_method='online'\n",
    ")\n",
    "\n",
    "print(\"Training LDA on ArXiv papers...\")\n",
    "lda_arxiv.fit(dtm_arxiv)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display topics\n",
    "def display_lda_topics(model, feature_names, n_words=12):\n",
    "    \"\"\"Display top words for each LDA topic.\"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words_idx = topic.argsort()[:-n_words-1:-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        print(f\"Topic {topic_idx}: {', '.join(top_words)}\")\n",
    "\n",
    "feature_names_arxiv = count_vec_arxiv.get_feature_names_out()\n",
    "print(\"ArXiv Paper Topics (LDA):\")\n",
    "print(\"=\" * 70)\n",
    "display_lda_topics(lda_arxiv, feature_names_arxiv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise C.1: Interpret ArXiv Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Assign meaningful labels to each topic based on the keywords\n",
    "\n",
    "my_arxiv_topic_labels = {\n",
    "    0: \"___\",  # YOUR LABEL\n",
    "    1: \"___\",  # YOUR LABEL\n",
    "    2: \"___\",  # YOUR LABEL\n",
    "    3: \"___\",  # YOUR LABEL\n",
    "    4: \"___\",  # YOUR LABEL\n",
    "    5: \"___\",  # YOUR LABEL\n",
    "    6: \"___\",  # YOUR LABEL\n",
    "    7: \"___\",  # YOUR LABEL\n",
    "    # Add more if n_topics_arxiv > 8\n",
    "}\n",
    "\n",
    "print(\"My Topic Interpretations:\")\n",
    "for topic_id, label in my_arxiv_topic_labels.items():\n",
    "    if label != \"___\":\n",
    "        print(f\"  Topic {topic_id}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.2 Advanced: Legal Contract Topic Discovery\n",
    "\n",
    "**Scenario:** A law firm discovers themes across contracts to organize their database.\n",
    "\n",
    "**Method:** NMF (Non-negative Matrix Factorization) - often better for shorter, specialized documents\n",
    "\n",
    "**Challenge:** Legal language is formal and domain-specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load legal contracts dataset (streaming to handle large size)\n",
    "print(\"Loading Legal Contracts dataset...\")\n",
    "legal_stream = load_dataset(\"albertvillanova/legal_contracts\", split=\"train\", streaming=True)\n",
    "\n",
    "# Take first 1500 contracts\n",
    "legal_contracts = []\n",
    "for i, item in enumerate(legal_stream):\n",
    "    if i >= 1500:\n",
    "        break\n",
    "    legal_contracts.append(item)\n",
    "\n",
    "legal_df = pd.DataFrame(legal_contracts)\n",
    "print(f\"Loaded {len(legal_df)} contracts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess legal text (truncate long documents)\n",
    "legal_df['text_truncated'] = legal_df['text'].str[:8000]  # Truncate\n",
    "legal_df['text_clean'] = legal_df['text_truncated'].apply(preprocess_advanced)\n",
    "\n",
    "print(\"Sample contract (cleaned, first 300 chars):\")\n",
    "print(legal_df.iloc[0]['text_clean'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise C.2: Build NMF Topic Model for Legal Contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create TF-IDF vectorizer for NMF (NMF works better with TF-IDF)\n",
    "\n",
    "tfidf_legal = None\n",
    "\n",
    "dtm_legal = tfidf_legal.fit_transform(legal_df['text_clean'])\n",
    "print(f\"Legal document-term matrix: {dtm_legal.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train NMF model\n",
    "# Choose number of topics (legal contracts may have: employment, confidentiality, IP, services, etc.)\n",
    "\n",
    "n_topics_legal = ___  # YOUR CHOICE: 5-12\n",
    "\n",
    "nmf_legal = NMF(\n",
    "    n_components=n_topics_legal,\n",
    "    random_state=42,\n",
    "    max_iter=200\n",
    ")\n",
    "\n",
    "print(f\"Training NMF with {n_topics_legal} topics...\")\n",
    "nmf_legal.fit(dtm_legal)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display NMF topics\n",
    "def display_nmf_topics(model, feature_names, n_words=12):\n",
    "    \"\"\"Display top words for each NMF topic.\"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words_idx = topic.argsort()[:-n_words-1:-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        print(f\"Topic {topic_idx}: {', '.join(top_words)}\")\n",
    "\n",
    "feature_names_legal = tfidf_legal.get_feature_names_out()\n",
    "print(f\"Legal Contract Topics (NMF, {n_topics_legal} topics):\")\n",
    "print(\"=\" * 70)\n",
    "display_nmf_topics(nmf_legal, feature_names_legal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Assign labels to legal topics\n",
    "\n",
    "my_legal_topic_labels = {}  # Add your labels: {0: \"label\", 1: \"label\", ...}\n",
    "\n",
    "# YOUR CODE HERE - fill the dictionary\n",
    "for i in range(n_topics_legal):\n",
    "    my_legal_topic_labels[i] = \"___\"  # Replace with your labels\n",
    "\n",
    "print(\"My Legal Topic Interpretations:\")\n",
    "for topic_id, label in my_legal_topic_labels.items():\n",
    "    if label != \"___\":\n",
    "        print(f\"  Topic {topic_id}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise C.3: Topic Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get document-topic distributions\n",
    "doc_topics_legal = nmf_legal.transform(dtm_legal)\n",
    "\n",
    "# Assign dominant topic\n",
    "legal_df['dominant_topic'] = doc_topics_legal.argmax(axis=1)\n",
    "\n",
    "# Visualize topic distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "topic_counts = legal_df['dominant_topic'].value_counts().sort_index()\n",
    "bars = plt.bar(topic_counts.index, topic_counts.values, color=plt.cm.Set3(range(len(topic_counts))))\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Number of Contracts')\n",
    "plt.title('Distribution of Contracts Across Topics')\n",
    "plt.xticks(range(n_topics_legal))\n",
    "\n",
    "# Add count labels\n",
    "for bar, count in zip(bars, topic_counts.values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
    "             str(count), ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('legal_topic_distribution.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written Question C.1 (Personal Interpretation)\n",
    "\n",
    "Compare ArXiv (LDA) vs Legal Contracts (NMF) topic modeling:\n",
    "\n",
    "1. **Which set of topics was easier to interpret?** Why?\n",
    "2. **Looking at the legal topic distribution, is it balanced?** What does this tell you about the contract dataset?\n",
    "3. **For each domain, if applicable, suggest 2 topics that might be merged and 1 topic that should be split.** Justify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER:**\n",
    "\n",
    "1. Easier to interpret:\n",
    "   - Domain: ...\n",
    "   - Reason: ...\n",
    "\n",
    "2. Legal topic distribution:\n",
    "   - Balanced? ...\n",
    "   - What this indicates: ...\n",
    "\n",
    "3. Topic refinement suggestions:\n",
    "   - ArXiv - Merge: Topics ___ and ___ because...\n",
    "   - ArXiv - Split: Topic ___ because...\n",
    "   - Legal - Merge: Topics ___ and ___ because...\n",
    "   - Legal - Split: Topic ___ because..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary - Lab 4 Part 2\n",
    "\n",
    "### Methods Summary\n",
    "\n",
    "| Task | Dataset | Feature Extraction | Model |\n",
    "|------|---------|-------------------|-------|\n",
    "| Classification (Intro) | AG News | TF-IDF | Logistic Regression |\n",
    "| Classification (Advanced) | LexGLUE | Bag of Words | Linear SVM |\n",
    "| Sentiment (Intro) | Amazon Reviews | TF-IDF | Naive Bayes |\n",
    "| Sentiment (Advanced) | Twitter | Character N-grams | Logistic Regression |\n",
    "| Topic Modeling (Intro) | ArXiv | Count Vectors | LDA |\n",
    "| Topic Modeling (Advanced) | Legal Contracts | TF-IDF | NMF |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Classification:** TF-IDF works well for standard text; specialized domains need careful preprocessing\n",
    "- **Sentiment:** Character n-grams help with informal/noisy text like tweets\n",
    "- **Topic Modeling:** LDA assumes documents have multiple topics; NMF often gives cleaner topics for specialized domains\n",
    "\n",
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "- [ ] All code exercises completed (fill all `___` placeholders)\n",
    "- [ ] **All written questions answered with YOUR personal interpretation**\n",
    "- [ ] All visualizations saved (PNG files)\n",
    "- [ ] Notebook saved\n",
    "- [ ] Pushed to Git repository\n",
    "- [ ] **Repository link sent to: yoroba93@gmail.com**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
