{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Part 1: Text Visualization & Classical Representations\n",
    "\n",
    "\n",
    "**Objectives:**\n",
    "- Visualize text data using bar charts, word clouds, and custom visualizations\n",
    "- Implement Bag of Words (BoW) and TF-IDF representations\n",
    "- Work with N-grams and build a simple next-word predictor\n",
    "- Analyze real news data and interpret results\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. Complete all exercises marked with `# YOUR CODE HERE`\n",
    "2. **Answer all written questions** in the designated markdown cells (these require YOUR personal interpretation)\n",
    "3. Save your completed notebook\n",
    "4. **Push to your Git repository and send the link to: yoroba93@gmail.com**\n",
    "\n",
    "### Important: Personal Interpretation Questions\n",
    "\n",
    "This lab contains **interpretation questions** that require YOUR own analysis. These questions:\n",
    "- Are based on YOUR specific results (which vary based on your choices)\n",
    "- Require you to explain your reasoning\n",
    "- Will be verified during an **oral defense session**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (uncomment if needed)\n",
    "# !pip install wordcloud matplotlib numpy pandas scikit-learn fsspec huggingface_hubpillow nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part A: Loading and Exploring the 20 Newsgroups Dataset (15 min)\n",
    "\n",
    "We will use the 20 Newsgroups dataset from Hugging Face. This dataset contains news articles from 20 different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (11314, 3)\n",
      "\n",
      "Columns: ['text', 'label', 'label_text']\n",
      "\n",
      "Label distribution:\n",
      "label_text\n",
      "rec.sport.hockey            600\n",
      "soc.religion.christian      599\n",
      "rec.motorcycles             598\n",
      "rec.sport.baseball          597\n",
      "sci.crypt                   595\n",
      "sci.med                     594\n",
      "rec.autos                   594\n",
      "sci.space                   593\n",
      "comp.windows.x              593\n",
      "comp.os.ms-windows.misc     591\n",
      "sci.electronics             591\n",
      "comp.sys.ibm.pc.hardware    590\n",
      "misc.forsale                585\n",
      "comp.graphics               584\n",
      "comp.sys.mac.hardware       578\n",
      "talk.politics.mideast       564\n",
      "talk.politics.guns          546\n",
      "alt.atheism                 480\n",
      "talk.politics.misc          465\n",
      "talk.religion.misc          377\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "splits = {'train': 'train.jsonl', 'test': 'test.jsonl'}\n",
    "## TODO: check on https://huggingface.co/datasets/SetFit/20_newsgroups how to load with pandas\n",
    "df = None  # YOUR CODE HERE\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['label_text'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document:\n",
      "==================================================\n",
      "Label: rec.autos\n",
      "Text (first 500 chars): I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail....\n"
     ]
    }
   ],
   "source": [
    "# View sample data\n",
    "print(\"Sample document:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Label: {df.iloc[0]['label_text']}\")\n",
    "print(f\"Text (first 500 chars): {df.iloc[0]['text'][:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A.1: Select YOUR Categories\n",
    "\n",
    "**Choose exactly 3 categories** from the dataset that YOU find interesting. This choice is personal and will affect all your subsequent analysis.\n",
    "\n",
    "**Available categories:**\n",
    "- alt.atheism, comp.graphics, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Choose YOUR 3 categories (this affects all your analysis!)\n",
    "# YOUR CODE HERE\n",
    "my_categories = [\"___\", \"___\", \"___\"]  # Replace with your choices\n",
    "\n",
    "# Filter the dataset\n",
    "df_filtered = df[df['label_text'].isin(my_categories)].copy()\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "print(f\"Selected categories: {my_categories}\")\n",
    "print(f\"Filtered dataset size: {len(df_filtered)}\")\n",
    "print(f\"\\nDistribution:\")\n",
    "print(df_filtered['label_text'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written Question A.1 (Personal Interpretation)\n",
    "\n",
    "**Why did you choose these 3 specific categories?** Explain your reasoning (at least 3 sentences).\n",
    "\n",
    "Consider:\n",
    "- Are they related or completely different?\n",
    "- What do you expect to find in terms of vocabulary differences?\n",
    "- Why are they interesting to YOU?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER:**\n",
    "\n",
    "*[Write your answer here - minimum 3 sentences]*\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part B: Text Preprocessing Function\n",
    "\n",
    "Before visualization, we need to clean our text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example preprocessing function\n",
    "# TODO: Complete the function as needed\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Basic text preprocessing.\"\"\"\n",
    "    # Lowercase\n",
    "    text = \"\" # YOUR CODE HERE\n",
    "    # Remove emails\n",
    "    text = \"\" # YOUR CODE HERE\n",
    "    # Remove URLs\n",
    "    text = \"\" # YOUR CODE HERE\n",
    "    # Remove numbers\n",
    "    text = \"\" # YOUR CODE HERE\n",
    "    # Remove punctuation\n",
    "    text = \"\" # YOUR CODE HERE\n",
    "    # Remove extra whitespace\n",
    "    text = \"\" # YOUR CODE HERE\n",
    "    return text\n",
    "\n",
    "# Test\n",
    "sample = \"Hello! Check this: http://example.com. Email me at test@email.com. Price: $100.\"\n",
    "print(f\"Original: {sample}\")\n",
    "print(f\"Cleaned:  {preprocess_text(sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B.1: Improve the Preprocessing Function\n",
    "\n",
    "The function above is basic. **Improve it** by adding:\n",
    "1. Stop word removal\n",
    "2. Lemmatization\n",
    "3. Minimum word length filter (remove words with < 3 characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete this improved preprocessing function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text_advanced(text):\n",
    "    \"\"\"\n",
    "    Advanced text preprocessing with stop words removal and lemmatization.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text\n",
    "    Returns:\n",
    "        str: Preprocessed text\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Step 1: Basic cleaning (lowercase, remove emails, URLs, numbers, punctuation)\n",
    "    \n",
    "    # Step 2: Tokenize\n",
    "    \n",
    "    # Step 3: Remove stop words\n",
    "    \n",
    "    # Step 4: Lemmatize\n",
    "    \n",
    "    # Step 5: Remove short words (< 3 chars)\n",
    "    \n",
    "    # Step 6: Join back to string\n",
    "    \n",
    "    return \"\"  # Replace with your result\n",
    "\n",
    "# Test your function\n",
    "sample = \"The cats are running quickly towards the beautiful gardens. Email: test@mail.com\"\n",
    "print(f\"Original: {sample}\")\n",
    "print(f\"Advanced: {preprocess_text_advanced(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to your filtered dataset\n",
    "df_filtered['text_clean'] = df_filtered['text'].apply(preprocess_text_advanced)\n",
    "\n",
    "# Show sample\n",
    "print(\"Sample preprocessed document:\")\n",
    "print(df_filtered.iloc[0]['text_clean'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part C: Text Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1 Bar Chart: Top Words per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(texts, n=15):\n",
    "    \"\"\"Get the n most common words from a list of texts.\"\"\"\n",
    "    all_words = ' '.join(texts).split()\n",
    "    word_counts = Counter(all_words)\n",
    "    return word_counts.most_common(n)\n",
    "\n",
    "# Get top words for each category\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, category in enumerate(my_categories):\n",
    "    texts = df_filtered[df_filtered['label_text'] == category]['text_clean'].tolist()\n",
    "    top_words = get_top_words(texts, 15)\n",
    "    \n",
    "    words, counts = zip(*top_words)\n",
    "    axes[idx].barh(words, counts, color=plt.cm.Set2(idx))\n",
    "    axes[idx].set_title(f'Top 15 Words: {category}')\n",
    "    axes[idx].invert_yaxis()\n",
    "    axes[idx].set_xlabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('top_words_by_category.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written Question C.1 (Personal Interpretation)\n",
    "\n",
    "Look at your bar charts above and answer:\n",
    "\n",
    "1. **What words are UNIQUE to each category?** (List at least 2 per category)\n",
    "2. **What words are SHARED across categories?** Why do you think they appear in multiple categories?\n",
    "3. **Based ONLY on the top words, could you guess the topic of each category?** Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER:**\n",
    "\n",
    "*Category 1 (___):*\n",
    "- Unique words: ...\n",
    "- \n",
    "\n",
    "*Category 2 (___):*\n",
    "- Unique words: ...\n",
    "- \n",
    "\n",
    "*Category 3 (___):*\n",
    "- Unique words: ...\n",
    "- \n",
    "\n",
    "*Shared words and explanation:*\n",
    "...\n",
    "\n",
    "*Topic guessing analysis:*\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2 Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple word cloud for each category\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "colors = ['Blues', 'Greens', 'Reds']\n",
    "\n",
    "for idx, category in enumerate(my_categories):\n",
    "    texts = df_filtered[df_filtered['label_text'] == category]['text_clean'].tolist()\n",
    "    text_combined = ' '.join(texts)\n",
    "    \n",
    "    wordcloud = WordCloud(\n",
    "        width=800, \n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        colormap=colors[idx],\n",
    "        max_words=100,\n",
    "        min_font_size=10\n",
    "    ).generate(text_combined)\n",
    "    \n",
    "    axes[idx].imshow(wordcloud, interpolation='bilinear')\n",
    "    axes[idx].set_title(f'Word Cloud: {category}', fontsize=14)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('wordclouds_by_category.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise C.2: Custom Shaped Word Cloud\n",
    "\n",
    "Create a word cloud using a **custom mask image**. \n",
    "\n",
    "**Instructions:**\n",
    "1. Find or create a simple black & white silhouette image (PNG format)\n",
    "2. Save it in your working directory\n",
    "3. Use it as a mask for your word cloud\n",
    "\n",
    "**Tip:** You can use any simple shape (circle, star, heart) or find free silhouettes online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating a circular mask programmatically\n",
    "# (You can replace this with your own image)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Create a circular mask\n",
    "def create_circle_mask(size=400):\n",
    "    x = np.arange(0, size)\n",
    "    y = np.arange(0, size)\n",
    "    cx, cy = size // 2, size // 2\n",
    "    r = size // 2 - 10\n",
    "    mask = np.zeros((size, size), dtype=np.uint8)\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            if (i - cx)**2 + (j - cy)**2 <= r**2:\n",
    "                mask[j, i] = 255\n",
    "    return mask\n",
    "\n",
    "circle_mask = create_circle_mask(400)\n",
    "\n",
    "# Show the mask\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(circle_mask, cmap='gray')\n",
    "plt.title('Circle Mask')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a custom word cloud with a mask\n",
    "# Choose ONE of your categories for this visualization\n",
    "\n",
    "# YOUR CODE HERE\n",
    "selected_category = \"___\"  # Choose one of your categories\n",
    "\n",
    "# Get texts for selected category\n",
    "texts = df_filtered[df_filtered['label_text'] == selected_category]['text_clean'].tolist()\n",
    "text_combined = ' '.join(texts)\n",
    "\n",
    "# Create word cloud with mask\n",
    "# Hint: Use the mask parameter in WordCloud()\n",
    "# wordcloud = WordCloud(..., mask=your_mask, ...).generate(text_combined)\n",
    "\n",
    "wordcloud_masked = None  # YOUR CODE HERE\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(10, 10))\n",
    "# YOUR CODE HERE - display the wordcloud\n",
    "plt.title(f'Custom Word Cloud: {selected_category}')\n",
    "plt.axis('off')\n",
    "plt.savefig('custom_wordcloud.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part D: Bag of Words (BoW) Representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simple Bag of Words\n",
    "sample_docs = [\n",
    "    \"I love machine learning\",\n",
    "    \"Machine learning is great\",\n",
    "    \"I love deep learning too\"\n",
    "]\n",
    "\n",
    "# Create BoW vectorizer\n",
    "bow_vectorizer = CountVectorizer()\n",
    "bow_matrix = bow_vectorizer.fit_transform(sample_docs)\n",
    "\n",
    "# Show vocabulary\n",
    "print(\"Vocabulary:\", bow_vectorizer.get_feature_names_out())\n",
    "print(\"\\nBoW Matrix (dense):\")\n",
    "print(bow_matrix.toarray())\n",
    "\n",
    "# As DataFrame\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=bow_vectorizer.get_feature_names_out())\n",
    "print(\"\\nAs DataFrame:\")\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise D.1: Create BoW for Your Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a Bag of Words representation for your filtered dataset\n",
    "# Use parameters: max_features=1000, min_df=5, max_df=0.95\n",
    "\n",
    "# YOUR CODE HERE\n",
    "bow_vectorizer_full = CountVectorizer(\n",
    "    # Add your parameters\n",
    ")\n",
    "\n",
    "# Fit and transform on your cleaned texts\n",
    "bow_matrix_full = None  # YOUR CODE HERE\n",
    "\n",
    "print(f\"BoW Matrix shape: {bow_matrix_full.shape}\")\n",
    "print(f\"Vocabulary size: {len(bow_vectorizer_full.get_feature_names_out())}\")\n",
    "print(f\"\\nFirst 20 words in vocabulary: {bow_vectorizer_full.get_feature_names_out()[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise D.2: Document Similarity with BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# TODO: Compute cosine similarity between documents\n",
    "# Then find the 2 most similar documents and the 2 most different documents\n",
    "\n",
    "# Compute similarity matrix\n",
    "similarity_matrix = None  # YOUR CODE HERE\n",
    "\n",
    "print(f\"Similarity matrix shape: {similarity_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the 2 most similar documents (excluding self-similarity)\n",
    "# Hint: Set diagonal to 0 or -1, then find argmax\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Find indices of most similar pair\n",
    "most_similar_idx = None  # (idx1, idx2)\n",
    "most_similar_score = None\n",
    "\n",
    "print(f\"Most similar documents: {most_similar_idx}\")\n",
    "print(f\"Similarity score: {most_similar_score}\")\n",
    "print(f\"\\nDocument 1 category: {df_filtered.iloc[most_similar_idx[0]]['label_text']}\")\n",
    "print(f\"Document 2 category: {df_filtered.iloc[most_similar_idx[1]]['label_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written Question D.1 (Personal Interpretation)\n",
    "\n",
    "Look at the 2 most similar documents you found:\n",
    "\n",
    "1. **Are they from the same category or different categories?**\n",
    "2. **Read the original texts (first 200 characters). What makes them similar?**\n",
    "3. **Is the BoW similarity measure meaningful here? Why or why not?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the similar documents for your analysis\n",
    "print(\"Document 1 (first 300 chars):\")\n",
    "print(df_filtered.iloc[most_similar_idx[0]]['text'][:300])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Document 2 (first 300 chars):\")\n",
    "print(df_filtered.iloc[most_similar_idx[1]]['text'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER:**\n",
    "\n",
    "*[Write your analysis here - answer all 3 questions]*\n",
    "\n",
    "1. Same or different category: ...\n",
    "\n",
    "2. What makes them similar: ...\n",
    "\n",
    "3. Is BoW meaningful here: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part E: TF-IDF Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: TF-IDF\n",
    "sample_docs = [\n",
    "    \"I love machine learning\",\n",
    "    \"Machine learning is great\",\n",
    "    \"I love deep learning too\"\n",
    "]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sample_docs)\n",
    "\n",
    "print(\"TF-IDF Matrix:\")\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(), \n",
    "    columns=tfidf_vectorizer.get_feature_names_out()\n",
    ")\n",
    "tfidf_df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare BoW vs TF-IDF for the word \"learning\"\n",
    "print(\"Word 'learning' scores:\")\n",
    "print(f\"  BoW:    {bow_df['learning'].tolist()}\")\n",
    "print(f\"  TF-IDF: {tfidf_df['learning'].round(3).tolist()}\")\n",
    "print(\"\\nNotice: TF-IDF gives LOWER scores to common words!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise E.1: TF-IDF Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create TF-IDF representation for your dataset\n",
    "# Use same parameters: max_features=1000, min_df=5, max_df=0.95\n",
    "\n",
    "tfidf_vectorizer_full = TfidfVectorizer(\n",
    "    # YOUR PARAMETERS HERE\n",
    ")\n",
    "\n",
    "tfidf_matrix_full = None  # YOUR CODE HERE\n",
    "\n",
    "print(f\"TF-IDF Matrix shape: {tfidf_matrix_full.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the top 10 most important words (highest TF-IDF) for each of your 3 categories\n",
    "\n",
    "def get_top_tfidf_words(category, n=10):\n",
    "    \"\"\"Get top n words by average TF-IDF score for a category.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Get indices of documents in this category\n",
    "    # 2. Get their TF-IDF vectors\n",
    "    # 3. Compute mean TF-IDF for each word across these documents\n",
    "    # 4. Return top n words\n",
    "    pass\n",
    "\n",
    "# Display top words for each category\n",
    "for category in my_categories:\n",
    "    top_words = get_top_tfidf_words(category, 10)\n",
    "    print(f\"\\nTop TF-IDF words for '{category}':\")\n",
    "    print(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written Question E.1 (Personal Interpretation)\n",
    "\n",
    "Compare the top words from TF-IDF vs the top words from simple word counts (bar charts):\n",
    "\n",
    "1. **What words appear in TF-IDF top 10 but NOT in the word count top 15?**\n",
    "2. **What words appear in word count top 15 but NOT in TF-IDF top 10?**\n",
    "3. **Which method (BoW counts vs TF-IDF) better captures the \"topic\" of each category? Explain why.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER:**\n",
    "\n",
    "*[Write your comparative analysis here]*\n",
    "\n",
    "1. Words in TF-IDF but not counts: ...\n",
    "\n",
    "2. Words in counts but not TF-IDF: ...\n",
    "\n",
    "3. Which method is better and why: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part F: N-grams and Next Word Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Extracting N-grams\n",
    "from nltk import ngrams\n",
    "\n",
    "sample_text = \"I love natural language processing and machine learning\"\n",
    "tokens = sample_text.split()\n",
    "\n",
    "# Bigrams (n=2)\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "print(\"Bigrams:\", bigrams)\n",
    "\n",
    "# Trigrams (n=3)\n",
    "trigrams = list(ngrams(tokens, 3))\n",
    "print(\"Trigrams:\", trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CountVectorizer for n-grams\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(2, 2))  # Only bigrams\n",
    "trigram_vectorizer = CountVectorizer(ngram_range=(3, 3))  # Only trigrams\n",
    "mixed_vectorizer = CountVectorizer(ngram_range=(1, 3))    # Unigrams, bigrams, and trigrams\n",
    "\n",
    "sample_docs = [\"I love machine learning\", \"Machine learning is great\"]\n",
    "\n",
    "bigrams_matrix = bigram_vectorizer.fit_transform(sample_docs)\n",
    "print(\"Bigram features:\", bigram_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise F.1: Analyze Bigrams in Your Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the top 15 most common bigrams for each of your categories\n",
    "\n",
    "bigram_vectorizer = CountVectorizer(\n",
    "    ngram_range=(2, 2),\n",
    "    max_features=500,\n",
    "    min_df=3\n",
    ")\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# For each category:\n",
    "# 1. Get the texts\n",
    "# 2. Fit the bigram vectorizer\n",
    "# 3. Find most common bigrams\n",
    "\n",
    "for category in my_categories:\n",
    "    texts = df_filtered[df_filtered['label_text'] == category]['text_clean'].tolist()\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    top_bigrams = []  # Get top 15 bigrams\n",
    "    \n",
    "    print(f\"\\nTop bigrams for '{category}':\")\n",
    "    for bigram, count in top_bigrams[:15]:\n",
    "        print(f\"  {bigram}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise F.2: Simple Next Word Predictor\n",
    "\n",
    "Build a simple next-word predictor using bigram probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build a bigram-based next word predictor\n",
    "\n",
    "class SimpleNextWordPredictor:\n",
    "    def __init__(self):\n",
    "        self.bigram_counts = {}  # {word1: {word2: count, word3: count, ...}}\n",
    "        self.unigram_counts = {}  # {word: count}\n",
    "    \n",
    "    def train(self, texts):\n",
    "        \"\"\"\n",
    "        Train the model on a list of texts.\n",
    "        \n",
    "        Args:\n",
    "            texts (list): List of preprocessed text strings\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # 1. For each text, tokenize into words\n",
    "        # 2. Count unigrams\n",
    "        # 3. Count bigrams (word pairs)\n",
    "        pass\n",
    "    \n",
    "    def predict_next(self, word, top_n=5):\n",
    "        \"\"\"\n",
    "        Predict the most likely next words given a word.\n",
    "        \n",
    "        Args:\n",
    "            word (str): The input word\n",
    "            top_n (int): Number of predictions to return\n",
    "            \n",
    "        Returns:\n",
    "            list: List of (next_word, probability) tuples\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # 1. Look up the word in bigram_counts\n",
    "        # 2. Calculate probabilities: P(word2|word1) = count(word1, word2) / count(word1)\n",
    "        # 3. Return top_n predictions sorted by probability\n",
    "        return []\n",
    "\n",
    "# Train on your dataset\n",
    "predictor = SimpleNextWordPredictor()\n",
    "predictor.train(df_filtered['text_clean'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your predictor with words relevant to your categories\n",
    "# TODO: Choose 5 test words that are relevant to YOUR chosen categories\n",
    "\n",
    "test_words = [\"___\", \"___\", \"___\", \"___\", \"___\"]  # Replace with your words\n",
    "\n",
    "print(\"Next Word Predictions:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for word in test_words:\n",
    "    predictions = predictor.predict_next(word.lower(), top_n=5)\n",
    "    print(f\"\\n'{word}' ->\")\n",
    "    for next_word, prob in predictions:\n",
    "        print(f\"  {next_word}: {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written Question F.1 (Personal Interpretation)\n",
    "\n",
    "Analyze your next-word predictor results:\n",
    "\n",
    "1. **Were the predictions sensible?** Give 2 examples of good predictions and 2 examples of bad predictions.\n",
    "2. **What are the limitations of this simple bigram model?**\n",
    "3. **How could you improve this predictor?** (List at least 3 ideas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER:**\n",
    "\n",
    "1. Good predictions:\n",
    "   - ...\n",
    "   - ...\n",
    "   \n",
    "   Bad predictions:\n",
    "   - ...\n",
    "   - ...\n",
    "\n",
    "2. Limitations: ...\n",
    "\n",
    "3. Improvement ideas:\n",
    "   - ...\n",
    "   - ...\n",
    "   - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part G: Document Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a correlation/similarity heatmap between documents\n",
    "# Sample 10 documents from each of your 3 categories (30 total)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample documents\n",
    "sampled_dfs = []\n",
    "for category in my_categories:\n",
    "    cat_df = df_filtered[df_filtered['label_text'] == category].sample(n=10, random_state=42)\n",
    "    sampled_dfs.append(cat_df)\n",
    "\n",
    "df_sampled = pd.concat(sampled_dfs).reset_index(drop=True)\n",
    "\n",
    "# Create TF-IDF for sampled documents\n",
    "tfidf_sampled = TfidfVectorizer(max_features=500).fit_transform(df_sampled['text_clean'])\n",
    "\n",
    "# Compute similarity matrix\n",
    "similarity_sampled = cosine_similarity(tfidf_sampled)\n",
    "\n",
    "# Create labels for heatmap\n",
    "labels = [f\"{cat[:6]}_{i}\" for cat, i in zip(df_sampled['label_text'], range(len(df_sampled)))]\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(\n",
    "    similarity_sampled, \n",
    "    xticklabels=labels, \n",
    "    yticklabels=labels,\n",
    "    cmap='YlOrRd',\n",
    "    annot=False\n",
    ")\n",
    "plt.title('Document Similarity Matrix (TF-IDF Cosine Similarity)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('document_similarity_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written Question G.1 (Personal Interpretation)\n",
    "\n",
    "Analyze the similarity heatmap:\n",
    "\n",
    "1. **Do documents from the same category cluster together?** (i.e., do you see bright squares along the diagonal for each category group?)\n",
    "2. **Which pair of categories is MOST similar to each other?** Which is LEAST similar?\n",
    "3. **Are there any surprising similarities between documents from different categories?** If yes, what might explain this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER:**\n",
    "\n",
    "1. Clustering observation: ...\n",
    "\n",
    "2. Most/Least similar category pairs: ...\n",
    "\n",
    "3. Surprising similarities: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary - Part 1\n",
    "\n",
    "In this lab, you learned:\n",
    "- How to visualize text data with bar charts and word clouds\n",
    "- Bag of Words (BoW) representation and document similarity\n",
    "- TF-IDF representation and its advantages over simple counts\n",
    "- N-grams and building a simple next-word predictor\n",
    "- Document correlation analysis\n",
    "\n",
    "---\n",
    "\n",
    "## Submission Checklist - Part 1\n",
    "\n",
    "- [ ] All code exercises completed\n",
    "- [ ] All written questions answered (with YOUR personal interpretation)\n",
    "- [ ] Visualizations saved (PNG files)\n",
    "- [ ] Notebook saved\n",
    "- [ ] Continue to Part 2 for Word Embeddings\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
